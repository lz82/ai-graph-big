{
  "expertVO": {
    "id": 1965672,
    "name": "William T. Freeman",
    "headImg": "/img/expert_logo/2018-06/2018-06-25-17-28-22__3ef00c13-e736-473c-ad3c-a264173f420b.jpg",
    "institution": "Massachusetts Institute of Technology",
    "subjectArea": "计算机科学",
    "country": "美国",
    "totalIssues": 187,
    "totalCitations": 20533,
    "top1Citations": 0.251337,
    "number1": 47,
    "top10Citations": 0.604278,
    "number10": 113,
    "hIndex": 62,
    "journalSend": null,
    "subjectMatch": null,
    "citedSituation": null,
    "fwciinedx": 7.207
  },
  "mapVO": {
    "nodes": [
      {"code":"0","name":"William T. Freeman","type":"expert","level":"1","colorIdx":"0"},
      {"code":"1","name":"荣誉","type":"honor","level":"2","colorIdx":"5"},
      {"code":"2","name":"机构","type":"org","level":"2","colorIdx":"6"},
      {"code":"3","name":"计算机视觉","type":"keyword","level":"2","colorIdx":"1"},
      {"code":"4","name":"神经网络","type":"keyword","level":"2","colorIdx":"2"},
      {"code":"5","name":"对抗网络","type":"keyword","level":"2","colorIdx":"3"}
      ],
    "relations": [
      {"id":"0","source":"0","target":"1"},
      {"id":"1","source":"0","target":"2"},
      {"id":"2","source":"0","target":"3"},
      {"id":"3","source":"0","target":"4"},
      {"id":"4","source":"0","target":"5"}
      ],
    "expertReco": null,
    "subjectReco": null,
    "journalsReco": null,
    "institutionsReco": null
  },
  "mapInfo": {
    "nodes": [
      {
        "id": "1059867_keyword",
        "name": "Standoff condition assessment",
        "type": "keyword",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "1659209_scholar",
        "name": "Charles lawrence Zitnick",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "665387_keyword",
        "name": "High speed video",
        "type": "keyword",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "118195_keyword",
        "name": "Piecewise smooth image model",
        "type": "keyword",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "436447_scholar",
        "name": "Youngjin Cha",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "2037626_scholar",
        "name": "Singbing Kang",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "912174_scholar",
        "name": "Neal Wadhwa",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "422515_scholar",
        "name": "刘策",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "861790_scholar",
        "name": "Frédo Durand",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "118193_keyword",
        "name": "Gaussian conditional random field",
        "type": "keyword",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "118196_keyword",
        "name": "Segmentation-based computer vision algorithms",
        "type": "keyword",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "1837414_scholar",
        "name": "Richard Szeliski",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "1965672_scholar",
        "name": "William T. Freeman",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      },
      {
        "id": "1909006_scholar",
        "name": "Oral Büyüköztürk",
        "type": "scholar",
        "value": 1,
        "releExpert": null,
        "releSubject": null
      }
    ],
    "relations": [
      {
        "source": "665387_keyword",
        "target": "861790_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "665387_keyword",
        "target": "1909006_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "1059867_keyword",
        "target": "436447_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "1965672_scholar",
        "target": "118195_keyword",
        "value": 1,
        "type": "keyword"
      },
      {
        "source": "1965672_scholar",
        "target": "118196_keyword",
        "value": 1,
        "type": "keyword"
      },
      {
        "source": "118195_keyword",
        "target": "1965672_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "118196_keyword",
        "target": "2037626_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "118195_keyword",
        "target": "1659209_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "1965672_scholar",
        "target": "118193_keyword",
        "value": 1,
        "type": "keyword"
      },
      {
        "source": "118195_keyword",
        "target": "422515_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "118195_keyword",
        "target": "1837414_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "1965672_scholar",
        "target": "1059867_keyword",
        "value": 1,
        "type": "keyword"
      },
      {
        "source": "665387_keyword",
        "target": "912174_scholar",
        "value": 1,
        "type": "scholar"
      },
      {
        "source": "1965672_scholar",
        "target": "665387_keyword",
        "value": 1,
        "type": "keyword"
      }
    ],
    "expertReco": null,
    "subjectReco": null,
    "journalsReco": null,
    "institutionsReco": null
  },
  "paperVO": [{
		"title": "Learning to Infer and Execute 3D Shape Programs.EI",
		"author": "Yonglong Tian, Andrew Luo, Xingyuan Sun, Kevin Ellis, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu",
		"publishDate": "CoRR(2019)",
		"summaryAll": "Human perception of 3D shapes goes beyond reconstructing them as a set of points or a composition of geometric primitives: we also effortlessly understand higher-level shape structure such as the repetition and reflective symmetry of object parts. In contrast, recent advances in 3D shape sensing focus more on low-level geometry but less on these higher-level relationships. "
	},
	{
		"title": "Unsupervised Discovery of Parts, Structure, and Dynamics.EI",
		"author": "Zhenjia Xu, Zhijian Liu, Chen Sun, Kevin Murphy, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu",
		"publishDate": "CoRR(2019)",
		"summaryAll": "Humans easily recognize object parts and their hierarchical structure by watching how they move; they can then predict how each part moves in the future. In this paper, we propose a novel formulation that simultaneously learns a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. "
	},
	{
		"title": "Visualizing and Understanding Generative Adversarial Networks (Extended Abstract).EI",
		"author": "David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenenbaum, William T. Freeman, Antonio Torralba",
		"publishDate": "CoRR(2019)",
		"summaryAll": "Generative Adversarial Networks (GANs) have achieved impressive results for many real-world applications. As an active research topic, many GAN variants have emerged with improvements in sample quality and training stability. However, visualization and understanding of GANs is largely missing. How does a GAN represent our visual world internally? What causes the artifacts in GAN results? How do architectural choices affect GAN learning? Answering such questions could enable us to develop new insights and better models. "
	},
	{
		"title": "Cognitive Load Estimation in the Wild.EI",
		"author": "Lex Fridman, Bryan Reimer, Bruce Mehler, William T. Freeman",
		"publishDate": "CHI(2018)",
		"summaryAll": "Cognitive load has been shown, over hundreds of validated studies, to be an important variable for understanding human performance. However, establishing practical, non-contact approaches for automated estimation of cognitive load under real-world conditions is far from a solved problem. Toward the goal of designing such a system, we propose two novel vision-based methods for cognitive load estimation, and evaluate them on a large-scale dataset collected under real-world driving conditions. "
	},
	{
		"title": "3D Interpreter Networks for Viewer-Centered Wireframe Modeling.EI",
		"author": "Jiajun Wu, Tianfan Xue, Joseph J. Lim, Yuandong Tian, Joshua B. Tenenbaum, Antonio Torralba, William T. Freeman",
		"publishDate": "International Journal of Computer Vision(2018)",
		"summaryAll": "Understanding 3D object structure from a single image is an important but challenging task in computer vision, mostly due to the lack of 3D object annotations to real images. Previous research tackled this problem by either searching for a 3D shape that best explains 2D annotations, or training purely on synthetic data with ground truth 3D information. In this work, we propose 3D INterpreter Networks (3D-INN), an end-to-end trainable framework that sequentially estimates 2D keypoint heatmaps and 3D object skeletons and poses. "
	},
	{
		"title": "Learning-based Video Motion Magnification.EI",
		"author": "Tae-Hyun Oh, Ronnachai Jaroensri, Changil Kim, Mohamed A. Elgharib, Frédo Durand, William T. Freeman, Wojciech Matusik",
		"publishDate": "ECCV(2018)",
		"summaryAll": "Video motion magnification techniques allow us to see small motions previously invisible to the naked eyes, such as those of vibrating airplane wings, or swaying buildings under the influence of the wind. Because the motion is small, the magnification results are prone to noise or excessive blurring. The state of the art relies on hand-designed filters to extract representations that may not be optimal. In this paper, we seek to learn the filters directly from examples using deep convolutional neural networks."
	},
	{
		"title": "Looking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation.EI",
		"author": "Ariel Ephrat, Inbar Mosseri, Oran Lang, Tali Dekel, Kevin Wilson, Avinatan Hassidim, William T. Freeman, Michael Rubinstein",
		"publishDate": "ACM Trans. Graph.(2018)",
		"summaryAll": "We present a joint audio-visual model for isolating a single speech signal from a mixture of sounds such as other speakers and background noise. Solving this task using only audio as input is extremely challenging and does not provide an association of the separated speech signals with speakers in the video."
	}
],
  "patentVO": null,
  "bookVO": [],
  "standardVO": []
}